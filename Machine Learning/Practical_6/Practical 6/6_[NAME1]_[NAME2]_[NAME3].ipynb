{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning - Practical 6\n",
    "\n",
    "Names: {YOUR NAMES}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-07-15T13:35:43.740Z",
     "iopub.status.busy": "2020-07-15T13:35:43.677Z",
     "iopub.status.idle": "2020-07-15T13:35:48.320Z",
     "shell.execute_reply": "2020-07-15T13:35:48.260Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(context='talk',style='white',palette='colorblind')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 0: Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To explore different clustering algorithms, we generated a toy dataset that consists of 5000 data points from a two dimensional mixture of Gaussian model with seven clusters.\n",
    "Plot the data points with different colors for each cluster and indicated the cluster means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "with open('data/data_gmms.pkl', 'rb') as f:\n",
    "    dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clustering(data, cluster_ids, means, title):\n",
    "    '''\n",
    "    Plots the (2D) data as scatter plot, with different colors and an extra symbol for the mean per cluster.\n",
    "    inputs:\n",
    "        data        -- (n_samples, n_features)-shaped array of data\n",
    "        cluster_ids -- (n_samples,)-shaped array of integers that hold the cluster assignment for each data point\n",
    "        means       -- (n_clusters, n_features)-shaped array of mean vectors\n",
    "        title       -- string that is added as title\n",
    "\n",
    "    '''\n",
    "\n",
    "    # ---------------- INSERT CODE ----------------------\n",
    "    \n",
    "    \n",
    "    \n",
    "    # ---------------- END CODE -------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_data = dataset['data']\n",
    "toy_cluster_ids_true = dataset['labels']\n",
    "toy_means = dataset['means']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_clustering(toy_data, toy_cluster_ids_true, toy_means, 'Toy dataset: Ground truth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Cluster the data using k-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will implement k-Means as an example of a simple clustering algorithm and see how it performs on the dataset. \n",
    "\n",
    "Use the function KMeans provided by sklearn to perform K-Means with different numbers of clusters, for instance 3, 5, 7, 10 and 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_KMeans(data, n_clusters):\n",
    "    '''Function that performs K-means clustering for a given number of clusters.\n",
    "        input:\n",
    "            data: (n_samples, n_features)-shaped array of data\n",
    "            number of clusters: int, number of clusters\n",
    "        output:\n",
    "            kmeans_result: (n_samples,)-shaped array of integers that hold the cluster assignment for each data point\n",
    "    '''\n",
    "\n",
    "    # ---------------- INSERT CODE ----------------------\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    # ---------------- END CODE -------------------------\n",
    "    return kmeans_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run kmeans with different numbers of clusters\n",
    "\n",
    "# ---------------- INSERT CODE ----------------------\n",
    "\n",
    "\n",
    "\n",
    "# ---------------- END CODE -------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot your results as cluster labels using the \"plot_clustering\" function and compare it to the original cluster labels. Describe your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot results\n",
    "# ---------------- INSERT CODE ----------------------\n",
    "\n",
    "\n",
    "\n",
    "# ---------------- END CODE -------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Task 2: Clustering using Gaussian Mixture Models\n",
    "\n",
    "Next, we will implement clustering with Gaussian Mixture models as discussed in the Bishop in Chapter 9.2.2 pg. 435-439."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the EM algorithm to fit a Gaussian mixture model on the data. Sort the data points by inferring their class labels from your mixture model (by using maximum a-posteriori classification). Fix the seed of the random number generator to ensure deterministic and reproducible behavior. \n",
    "\n",
    "For this task, it is important to think about a good way to initialize the means, covariances and mixing coefficients. Also, during optimization, covariance matrices can become singular. To prevent this, you can add a small constant (like $10^{-5}$) to the diagonal.\n",
    "\n",
    "In order to speed up the computation, define a convergence criterion that stops the algorithm after convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gmm(data, n_clusters, verbose=True, max_iter=1000, convergence_threshold=1e-4):\n",
    "    '''Function that fits a mixture of gaussians to data.\n",
    "\n",
    "        inputs:\n",
    "            data          -- (n_samples, n_features)-shaped array of data points\n",
    "            n_clusters    -- int, number of clusters / mixture components\n",
    "            verbose       -- bool, if True, print current likelihood after each EM iteration\n",
    "            max_iter      -- maximum number of EM iterations\n",
    "            convergence_threshold  -- stop algorithm if change in log-lieklihood is below the treshold\n",
    "\n",
    "        outputs:\n",
    "            cluster_ids -- (n_samples,)-shaped array of integers that hold the cluster assignment for each data point\n",
    "            means       -- (n_clusters, n_features)-shaped array of fit mean vectors\n",
    "            covs        -- (n_features, n_features, n_clusters)-shaped array of fit covariance matrices\n",
    "            priors      -- (n_clusters)-shaped arrays of fit priors / mixing coefficients\n",
    "        '''\n",
    "\n",
    "    # ---------------- INSERT CODE ----------------------\n",
    "\n",
    "    ### INITIALIZATION ###\n",
    "\n",
    "\n",
    "    ### ALTERNATE BETWEEN E & M STEP ###\n",
    "    \n",
    "\n",
    "        ### E-STEP ###\n",
    "        \n",
    "\n",
    "        ### M-STEP ###\n",
    "        \n",
    "\n",
    "        ### CHECK FOR CONVERGENCE/ PRINT LOG_LIKELIHOOD if VERBOSE ###\n",
    "        \n",
    "\n",
    "    ### ASSIGN CLUSTER LABELS ###\n",
    "\n",
    "\n",
    "    # ---------------- END CODE -------------------------\n",
    "\n",
    "    return (cluster_ids, means, covs, priors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore the results of GMM using different numbers of clusters and initialization strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit GMM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the data points from the toy dataset and indicate in color the cluster each point was assigned to by your model. How does the assignment compare to ground truth? How does it compare to the k-Means solution? Plot ground truth, k-Means and GMM cluster assignment side-by-side to compare them.\n",
    "\n",
    "If you run the algorithm multiple times, you will notice that some solutions provide suboptimal clustering solutions - depending on your initialization strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "nteract": {
   "version": "0.24.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
